{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set randomness for reproducibility\n",
    "from numpy.random import seed\n",
    "seed(8) #1\n",
    "#import tensorflow as tf\n",
    "#tf.set_random_seed(7)\n",
    "\n",
    "#\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['covid', 'normal', 'pneumonia_bac', 'pneumonia_vir']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "data_list = listdir('content/all/train')\n",
    "\n",
    "#Delete some classes that may interfere\n",
    "\n",
    "\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\kpbab\\Anaconda3\\envs\\covid-19-detector-testing\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:341: UserWarning: This ImageDataGenerator specifies `zca_whitening` which overrides setting of`featurewise_std_normalization`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 4 classes.\n",
      "Found 54 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model ,load_model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "DATASET_PATH  = 'content/all/train'\n",
    "test_dir =  'content/all/test'\n",
    "IMAGE_SIZE    = (150, 150)\n",
    "NUM_CLASSES   = len(data_list)\n",
    "BATCH_SIZE    = 10  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "NUM_EPOCHS    = 100\n",
    "LEARNING_RATE =0.0001\n",
    "\n",
    "\n",
    "\n",
    "#Train datagen here is a preprocessor\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=50,\n",
    "                                   featurewise_center = True,\n",
    "                                   featurewise_std_normalization = True,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.25,\n",
    "                                   zoom_range=0.1,\n",
    "                                   zca_whitening = True,\n",
    "                                   channel_shift_range = 20,\n",
    "                                   horizontal_flip = True ,\n",
    "                                   vertical_flip = True ,\n",
    "                                   validation_split = 0.2,\n",
    "                                   fill_mode='constant')\n",
    "\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH,\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"training\",\n",
    "                                                  seed=42,\n",
    "                                                  class_mode=\"categorical\"\n",
    "                                                  )\n",
    "\n",
    "valid_batches = train_datagen.flow_from_directory(DATASET_PATH,\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"validation\",\n",
    "                                                  seed=42,\n",
    "                                                  class_mode=\"categorical\"\n",
    "                                                 \n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.applications import VGG16\n",
    "from keras import optimizers\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))\n",
    "\n",
    "\n",
    "conv_base.trainable = False\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              \n",
    "              optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 16,812,867\n",
      "Trainable params: 2,098,179\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `batch_size` argument must not be specified when using a generator or Sequence as an input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-39fa19951f04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m                  \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                  \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                  \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                  )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\covid-19-detector-testing\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m         batch_size = self._validate_or_infer_batch_size(\n\u001b[1;32m-> 1126\u001b[1;33m             batch_size, steps_per_epoch, x)\n\u001b[0m\u001b[0;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[1;31m# Case 1: generator-like. Input is Python generator,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\covid-19-detector-testing\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_validate_or_infer_batch_size\u001b[1;34m(self, batch_size, steps, x)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \"\"\"\n\u001b[0;32m    911\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_generator_or_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m             raise ValueError('The `batch_size` argument must not be specified when'\n\u001b[0m\u001b[0;32m    913\u001b[0m                              ' using a generator or Sequence as an input.')\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The `batch_size` argument must not be specified when using a generator or Sequence as an input."
     ]
    }
   ],
   "source": [
    "#FIT MODEL\n",
    "print(len(train_batches))\n",
    "print(len(valid_batches))\n",
    "\n",
    "STEP_SIZE_TRAIN=train_batches.n//train_batches.batch_size\n",
    "STEP_SIZE_VALID=valid_batches.n//valid_batches.batch_size\n",
    "\n",
    "#result=model.fit_generator(train_batches,\n",
    "#                       steps_per_epoch =STEP_SIZE_TRAIN,\n",
    "#                        validation_data = valid_batches,\n",
    "#                        validation_steps = STEP_SIZE_VALID,\n",
    "#                        epochs= NUM_EPOCHS,                        \n",
    "#                       )\n",
    "result=model.fit(x=train_batches, \n",
    "                 y=None, \n",
    "                 batch_size=10, \n",
    "                 epochs=NUM_EPOCHS, \n",
    "                 verbose=1, \n",
    "                 callbacks=None, \n",
    "                 validation_split=0.0, \n",
    "                 validation_data=valid_batches, \n",
    "                 shuffle=True, \n",
    "                 class_weight=None, \n",
    "                 sample_weight=None, \n",
    "                 initial_epoch=0, \n",
    "                 steps_per_epoch=None, \n",
    "                 validation_steps=None, \n",
    "                 validation_freq=1, \n",
    "                 max_queue_size=10, \n",
    "                 workers=1, \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-8bbbbce4442a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mplot_acc_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_acc_loss(result, epochs):\n",
    "    acc = result.history['acc']\n",
    "    loss = result.history['loss']\n",
    "    val_acc = result.history['val_acc']\n",
    "    val_loss = result.history['val_loss']\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(range(1,epochs), acc[1:], label='Train_acc')\n",
    "    plt.plot(range(1,epochs), val_acc[1:], label='Test_acc')\n",
    "    plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.subplot(122)\n",
    "    plt.plot(range(1,epochs), loss[1:], label='Train_loss')\n",
    "    plt.plot(range(1,epochs), val_loss[1:], label='Test_loss')\n",
    "    plt.title('Loss over ' + str(epochs) + ' Epochs', size=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "plot_acc_loss(result, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
